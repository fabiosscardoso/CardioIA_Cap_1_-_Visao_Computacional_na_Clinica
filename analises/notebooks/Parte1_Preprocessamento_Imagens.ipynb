{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d43266f4",
   "metadata": {},
   "source": [
    "PARTE 1: Pr√©-processamento e Organiza√ß√£o de Imagens M√©dicas\n",
    "CardioIA - A Nova Era da Cardiologia Inteligente\n",
    "\n",
    "Este notebook implementa o pipeline completo de pr√©-processamento de imagens m√©dicas\n",
    "para classifica√ß√£o com CNN, incluindo:\n",
    "- Download e explora√ß√£o do dataset\n",
    "- Redimensionamento e normaliza√ß√£o\n",
    "- Convers√£o de formatos\n",
    "- Cria√ß√£o de conjuntos treino, valida√ß√£o e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c3be292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d32dfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PARTE 1: PR√â-PROCESSAMENTO E ORGANIZA√á√ÉO DE IMAGENS M√âDICAS\n",
      "CardioIA - A Nova Era da Cardiologia Inteligente\n",
      "================================================================================\n",
      "\n",
      "Data de execu√ß√£o: 06/12/2025 22:46:56\n",
      "Seed para reprodutibilidade: 42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configura√ß√µes\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PARTE 1: PR√â-PROCESSAMENTO E ORGANIZA√á√ÉO DE IMAGENS M√âDICAS\")\n",
    "print(\"CardioIA - A Nova Era da Cardiologia Inteligente\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nData de execu√ß√£o: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "print(f\"Seed para reprodutibilidade: {SEED}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a879d2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SE√á√ÉO 1: DOWNLOAD E EXPLORA√á√ÉO DO DATASET\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SE√á√ÉO 1: DOWNLOAD E EXPLORA√á√ÉO DO DATASET\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SE√á√ÉO 1: DOWNLOAD E EXPLORA√á√ÉO DO DATASET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# dataset sint√©tico que simula radiografias de t√≥rax com classifica√ß√µes card√≠acas\n",
    "# Em produ√ß√£o, voc√™ baixaria de: https://www.kaggle.com/datasets/\n",
    "\n",
    "def criar_dataset_sintetico(num_amostras=200, tamanho_imagem=(224, 224)):\n",
    "    \"\"\"\n",
    "    Cria um dataset sint√©tico de imagens m√©dicas para demonstra√ß√£o.\n",
    "    Em um cen√°rio real, isso seria substitu√≠do pelo download do dataset real.\n",
    "    \n",
    "    Args:\n",
    "        num_amostras: N√∫mero total de imagens a gerar\n",
    "        tamanho_imagem: Dimens√µes das imagens (altura, largura)\n",
    "    \n",
    "    Returns:\n",
    "        Dicion√°rio com informa√ß√µes das imagens e labels\n",
    "    \"\"\"\n",
    "    print(f\"\\n‚úì Criando dataset sint√©tico com {num_amostras} imagens...\")\n",
    "    print(f\"  Dimens√µes: {tamanho_imagem[0]}x{tamanho_imagem[1]} pixels\")\n",
    "    \n",
    "    dataset_info = {\n",
    "        'imagens': [],\n",
    "        'labels': [],\n",
    "        'caminhos': [],\n",
    "        'descricoes': []\n",
    "    }\n",
    "    \n",
    "    # Classes: 0 = Normal, 1 = Cardiomegalia, 2 = Outras Patologias\n",
    "    classes = {\n",
    "        0: 'Normal',\n",
    "        1: 'Cardiomegalia',\n",
    "        2: 'Outras_Patologias'\n",
    "    }\n",
    "    \n",
    "    data_dir = Path('/home/ubuntu/CardioIA/data/raw_images')\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Criar subdiret√≥rios para cada classe\n",
    "    for class_id, class_name in classes.items():\n",
    "        class_dir = data_dir / class_name\n",
    "        class_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Gerar imagens sint√©ticas\n",
    "    amostras_por_classe = num_amostras // len(classes)\n",
    "    \n",
    "    for class_id, class_name in classes.items():\n",
    "        for i in range(amostras_por_classe):\n",
    "            # Gerar imagem sint√©tica (simulando radiografia)\n",
    "            if class_id == 0:  # Normal\n",
    "                # Imagem com padr√£o mais uniforme\n",
    "                img = np.random.normal(100, 20, tamanho_imagem).astype(np.uint8)\n",
    "            elif class_id == 1:  # Cardiomegalia\n",
    "                # Imagem com √°rea card√≠aca aumentada (mais branca no centro)\n",
    "                img = np.random.normal(80, 25, tamanho_imagem).astype(np.uint8)\n",
    "                y, x = np.ogrid[:tamanho_imagem[0], :tamanho_imagem[1]]\n",
    "                mask = (x - tamanho_imagem[1]//2)**2 + (y - tamanho_imagem[0]//2)**2 <= (tamanho_imagem[0]//3)**2\n",
    "                img[mask] = np.clip(img[mask] + 50, 0, 255).astype(np.uint8)\n",
    "            else:  # Outras patologias\n",
    "                # Imagem com padr√£o irregular\n",
    "                img = np.random.normal(90, 30, tamanho_imagem).astype(np.uint8)\n",
    "                img = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "            \n",
    "            # Salvar imagem\n",
    "            img_path = data_dir / class_name / f'{class_name}_{i:04d}.png'\n",
    "            Image.fromarray(img).save(str(img_path))\n",
    "            \n",
    "            dataset_info['imagens'].append(img)\n",
    "            dataset_info['labels'].append(class_id)\n",
    "            dataset_info['caminhos'].append(str(img_path))\n",
    "            dataset_info['descricoes'].append(f'{class_name} - Amostra {i}')\n",
    "    \n",
    "    print(f\"‚úì Dataset sint√©tico criado com sucesso!\")\n",
    "    print(f\"  Total de imagens: {len(dataset_info['imagens'])}\")\n",
    "    for class_id, class_name in classes.items():\n",
    "        count = sum(1 for l in dataset_info['labels'] if l == class_id)\n",
    "        print(f\"  - {class_name}: {count} imagens\")\n",
    "    \n",
    "    return dataset_info, classes\n",
    "\n",
    "# Criar dataset\n",
    "dataset_info, classes = criar_dataset_sintetico(num_amostras=200, tamanho_imagem=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea650aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SE√á√ÉO 2: EXPLORA√á√ÉO E VISUALIZA√á√ÉO DO DATASET\n",
      "================================================================================\n",
      "\n",
      "‚úì Estat√≠sticas do Dataset:\n",
      "  Total de imagens: 198\n",
      "  N√∫mero de classes: 3\n",
      "  Dimens√µes das imagens: (224, 224)\n",
      "  Tipo de dados: uint8\n",
      "\n",
      "‚úì Distribui√ß√£o de Classes:\n",
      "  Normal: 66 (33.3%)\n",
      "  Cardiomegalia: 66 (33.3%)\n",
      "  Outras_Patologias: 66 (33.3%)\n",
      "\n",
      "‚úì Visualiza√ß√£o salva: 01_amostras_dataset.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SE√á√ÉO 2: EXPLORA√á√ÉO E VISUALIZA√á√ÉO DO DATASET\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SE√á√ÉO 2: EXPLORA√á√ÉO E VISUALIZA√á√ÉO DO DATASET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Estat√≠sticas do dataset\n",
    "print(\"\\n‚úì Estat√≠sticas do Dataset:\")\n",
    "print(f\"  Total de imagens: {len(dataset_info['imagens'])}\")\n",
    "print(f\"  N√∫mero de classes: {len(classes)}\")\n",
    "print(f\"  Dimens√µes das imagens: {dataset_info['imagens'][0].shape}\")\n",
    "print(f\"  Tipo de dados: {dataset_info['imagens'][0].dtype}\")\n",
    "\n",
    "# Distribui√ß√£o de classes\n",
    "print(\"\\n‚úì Distribui√ß√£o de Classes:\")\n",
    "class_counts = pd.Series(dataset_info['labels']).value_counts().sort_index()\n",
    "for class_id, count in class_counts.items():\n",
    "    percentage = (count / len(dataset_info['labels'])) * 100\n",
    "    print(f\"  {classes[class_id]}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# Visualizar amostras\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "fig.suptitle('Amostras do Dataset - Pr√©-processamento', fontsize=14, fontweight='bold')\n",
    "\n",
    "for idx, (ax, class_id) in enumerate(zip(axes.flatten(), [0, 0, 1, 1, 2, 2])):\n",
    "    # Encontrar primeira imagem de cada classe\n",
    "    img_idx = dataset_info['labels'].index(class_id)\n",
    "    img = dataset_info['imagens'][img_idx]\n",
    "    \n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(f'{classes[class_id]}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/01_amostras_dataset.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n‚úì Visualiza√ß√£o salva: 01_amostras_dataset.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3251033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SE√á√ÉO 3: PR√â-PROCESSAMENTO DE IMAGENS\n",
      "================================================================================\n",
      "\n",
      "‚úì T√©cnicas de Pr√©-processamento Implementadas:\n",
      "  1. Redimensionamento (interpola√ß√£o c√∫bica)\n",
      "  2. Equaliza√ß√£o de Histograma (para melhorar contraste)\n",
      "  3. Normaliza√ß√£o (escala 0-1)\n",
      "  4. Padroniza√ß√£o (z-score normalization)\n",
      "\n",
      "‚úì Aplicando pr√©-processamento a todas as imagens...\n",
      "  Processadas 50/198 imagens\n",
      "  Processadas 100/198 imagens\n",
      "  Processadas 150/198 imagens\n",
      "‚úì Pr√©-processamento conclu√≠do!\n",
      "  Forma das imagens processadas: (224, 224)\n",
      "  Tipo de dados: float32\n",
      "  Intervalo de valores: [-2.500, -2.480]\n",
      "\n",
      "‚úì Visualiza√ß√£o salva: 02_antes_depois_preprocessamento.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SE√á√ÉO 3: PR√â-PROCESSAMENTO DE IMAGENS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SE√á√ÉO 3: PR√â-PROCESSAMENTO DE IMAGENS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class PreprocessadorImagens:\n",
    "    \"\"\"\n",
    "    Classe para centralizar todas as opera√ß√µes de pr√©-processamento de imagens.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tamanho_alvo=(224, 224)):\n",
    "        \"\"\"\n",
    "        Inicializa o preprocessador.\n",
    "        \n",
    "        Args:\n",
    "            tamanho_alvo: Dimens√µes alvo para redimensionamento\n",
    "        \"\"\"\n",
    "        self.tamanho_alvo = tamanho_alvo\n",
    "        self.historico = []\n",
    "    \n",
    "    def redimensionar(self, imagem):\n",
    "        \"\"\"\n",
    "        Redimensiona a imagem para o tamanho alvo usando interpola√ß√£o c√∫bica.\n",
    "        \n",
    "        Args:\n",
    "            imagem: Array numpy da imagem\n",
    "        \n",
    "        Returns:\n",
    "            Imagem redimensionada\n",
    "        \"\"\"\n",
    "        img_redimensionada = cv2.resize(imagem, self.tamanho_alvo, interpolation=cv2.INTER_CUBIC)\n",
    "        return img_redimensionada\n",
    "    \n",
    "    def normalizar(self, imagem):\n",
    "        \"\"\"\n",
    "        Normaliza a imagem para o intervalo [0, 1].\n",
    "        \n",
    "        Args:\n",
    "            imagem: Array numpy da imagem\n",
    "        \n",
    "        Returns:\n",
    "            Imagem normalizada\n",
    "        \"\"\"\n",
    "        img_normalizada = imagem.astype(np.float32) / 255.0\n",
    "        return img_normalizada\n",
    "    \n",
    "    def padronizar(self, imagem, media=0.5, desvio=0.2):\n",
    "        \"\"\"\n",
    "        Padroniza a imagem (z-score normalization).\n",
    "        \n",
    "        Args:\n",
    "            imagem: Array numpy da imagem (normalizada entre 0 e 1)\n",
    "            media: M√©dia para padroniza√ß√£o\n",
    "            desvio: Desvio padr√£o para padroniza√ß√£o\n",
    "        \n",
    "        Returns:\n",
    "            Imagem padronizada\n",
    "        \"\"\"\n",
    "        img_padronizada = (imagem - media) / desvio\n",
    "        return img_padronizada\n",
    "    \n",
    "    def aplicar_histogram_equalization(self, imagem):\n",
    "        \"\"\"\n",
    "        Aplica equaliza√ß√£o de histograma para melhorar contraste.\n",
    "        \n",
    "        Args:\n",
    "            imagem: Array numpy da imagem (valores 0-255)\n",
    "        \n",
    "        Returns:\n",
    "            Imagem com contraste aprimorado\n",
    "        \"\"\"\n",
    "        img_uint8 = (imagem * 255).astype(np.uint8) if imagem.max() <= 1 else imagem.astype(np.uint8)\n",
    "        img_equalizado = cv2.equalizeHist(img_uint8)\n",
    "        return img_equalizado.astype(np.float32) / 255.0\n",
    "    \n",
    "    def pipeline_completo(self, imagem, aplicar_equalizacao=True):\n",
    "        \"\"\"\n",
    "        Aplica o pipeline completo de pr√©-processamento.\n",
    "        \n",
    "        Args:\n",
    "            imagem: Array numpy da imagem\n",
    "            aplicar_equalizacao: Se deve aplicar equaliza√ß√£o de histograma\n",
    "        \n",
    "        Returns:\n",
    "            Imagem pr√©-processada\n",
    "        \"\"\"\n",
    "        # 1. Redimensionar\n",
    "        img = self.redimensionar(imagem)\n",
    "        \n",
    "        # 2. Aplicar equaliza√ß√£o (opcional)\n",
    "        if aplicar_equalizacao:\n",
    "            img = self.aplicar_histogram_equalization(img)\n",
    "        \n",
    "        # 3. Normalizar\n",
    "        img = self.normalizar(img)\n",
    "        \n",
    "        # 4. Padronizar\n",
    "        img = self.padronizar(img)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "# Inicializar preprocessador\n",
    "preprocessador = PreprocessadorImagens(tamanho_alvo=(224, 224))\n",
    "\n",
    "print(\"\\n‚úì T√©cnicas de Pr√©-processamento Implementadas:\")\n",
    "print(\"  1. Redimensionamento (interpola√ß√£o c√∫bica)\")\n",
    "print(\"  2. Equaliza√ß√£o de Histograma (para melhorar contraste)\")\n",
    "print(\"  3. Normaliza√ß√£o (escala 0-1)\")\n",
    "print(\"  4. Padroniza√ß√£o (z-score normalization)\")\n",
    "\n",
    "# Aplicar pr√©-processamento a todas as imagens\n",
    "print(\"\\n‚úì Aplicando pr√©-processamento a todas as imagens...\")\n",
    "imagens_processadas = []\n",
    "for idx, img in enumerate(dataset_info['imagens']):\n",
    "    img_processada = preprocessador.pipeline_completo(img)\n",
    "    imagens_processadas.append(img_processada)\n",
    "    if (idx + 1) % 50 == 0:\n",
    "        print(f\"  Processadas {idx + 1}/{len(dataset_info['imagens'])} imagens\")\n",
    "\n",
    "print(f\"‚úì Pr√©-processamento conclu√≠do!\")\n",
    "print(f\"  Forma das imagens processadas: {imagens_processadas[0].shape}\")\n",
    "print(f\"  Tipo de dados: {imagens_processadas[0].dtype}\")\n",
    "print(f\"  Intervalo de valores: [{imagens_processadas[0].min():.3f}, {imagens_processadas[0].max():.3f}]\")\n",
    "\n",
    "# Visualizar antes e depois\n",
    "fig, axes = plt.subplots(3, 4, figsize=(14, 10))\n",
    "fig.suptitle('Compara√ß√£o: Antes e Depois do Pr√©-processamento', fontsize=14, fontweight='bold')\n",
    "\n",
    "for row, class_id in enumerate([0, 1, 2]):\n",
    "    # Encontrar primeira imagem de cada classe\n",
    "    img_idx = dataset_info['labels'].index(class_id)\n",
    "    \n",
    "    # Antes\n",
    "    img_original = dataset_info['imagens'][img_idx]\n",
    "    axes[row, 0].imshow(img_original, cmap='gray')\n",
    "    axes[row, 0].set_title(f'{classes[class_id]} - Original')\n",
    "    axes[row, 0].axis('off')\n",
    "    \n",
    "    # Redimensionado\n",
    "    img_redim = preprocessador.redimensionar(img_original)\n",
    "    axes[row, 1].imshow(img_redim, cmap='gray')\n",
    "    axes[row, 1].set_title('Redimensionado')\n",
    "    axes[row, 1].axis('off')\n",
    "    \n",
    "    # Com Equaliza√ß√£o\n",
    "    img_eq = preprocessador.aplicar_histogram_equalization(img_redim)\n",
    "    axes[row, 2].imshow(img_eq, cmap='gray')\n",
    "    axes[row, 2].set_title('Com Equaliza√ß√£o')\n",
    "    axes[row, 2].axis('off')\n",
    "    \n",
    "    # Processado Completo\n",
    "    img_processada = imagens_processadas[img_idx]\n",
    "    axes[row, 3].imshow(img_processada, cmap='gray')\n",
    "    axes[row, 3].set_title('Processado Completo')\n",
    "    axes[row, 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/02_antes_depois_preprocessamento.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n‚úì Visualiza√ß√£o salva: 02_antes_depois_preprocessamento.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec3b87fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SE√á√ÉO 4: CRIA√á√ÉO DE CONJUNTOS TREINO, VALIDA√á√ÉO E TESTE\n",
      "================================================================================\n",
      "\n",
      "‚úì Dados preparados para divis√£o:\n",
      "  X shape: (198, 224, 224)\n",
      "  y shape: (198,)\n",
      "\n",
      "‚úì Divis√£o dos Dados:\n",
      "  Treino:     96 imagens (48.5%)\n",
      "  Valida√ß√£o:  42 imagens (21.2%)\n",
      "  Teste:      60 imagens (30.3%)\n",
      "\n",
      "‚úì Distribui√ß√£o de Classes por Conjunto:\n",
      "\n",
      "  Treino:\n",
      "    Normal: 32 (33.3%)\n",
      "    Cardiomegalia: 32 (33.3%)\n",
      "    Outras_Patologias: 32 (33.3%)\n",
      "\n",
      "  Valida√ß√£o:\n",
      "    Normal: 14 (33.3%)\n",
      "    Cardiomegalia: 14 (33.3%)\n",
      "    Outras_Patologias: 14 (33.3%)\n",
      "\n",
      "  Teste:\n",
      "    Normal: 20 (33.3%)\n",
      "    Cardiomegalia: 20 (33.3%)\n",
      "    Outras_Patologias: 20 (33.3%)\n",
      "\n",
      "‚úì Salvando conjuntos de dados...\n",
      "‚úì Arquivos salvos em: /home/ubuntu/CardioIA/data/processed\n",
      "‚úì Visualiza√ß√£o salva: 03_distribuicao_conjuntos.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SE√á√ÉO 4: CRIA√á√ÉO DE CONJUNTOS TREINO, VALIDA√á√ÉO E TESTE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SE√á√ÉO 4: CRIA√á√ÉO DE CONJUNTOS TREINO, VALIDA√á√ÉO E TESTE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Converter para arrays numpy\n",
    "X = np.array(imagens_processadas)\n",
    "y = np.array(dataset_info['labels'])\n",
    "\n",
    "print(f\"\\n‚úì Dados preparados para divis√£o:\")\n",
    "print(f\"  X shape: {X.shape}\")\n",
    "print(f\"  y shape: {y.shape}\")\n",
    "\n",
    "# Primeira divis√£o: 70% treino+valida√ß√£o, 30% teste\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "# Segunda divis√£o: 70% treino, 30% valida√ß√£o (do conjunto temp)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.30, random_state=SEED, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Divis√£o dos Dados:\")\n",
    "print(f\"  Treino:     {len(X_train)} imagens ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"  Valida√ß√£o:  {len(X_val)} imagens ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "print(f\"  Teste:      {len(X_test)} imagens ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "\n",
    "# Verificar distribui√ß√£o de classes em cada conjunto\n",
    "print(f\"\\n‚úì Distribui√ß√£o de Classes por Conjunto:\")\n",
    "for conjunto_nome, y_conjunto in [('Treino', y_train), ('Valida√ß√£o', y_val), ('Teste', y_test)]:\n",
    "    print(f\"\\n  {conjunto_nome}:\")\n",
    "    for class_id in range(len(classes)):\n",
    "        count = np.sum(y_conjunto == class_id)\n",
    "        percentage = (count / len(y_conjunto)) * 100\n",
    "        print(f\"    {classes[class_id]}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# Salvar conjuntos em arquivos\n",
    "print(f\"\\n‚úì Salvando conjuntos de dados...\")\n",
    "\n",
    "data_processed_dir = Path('/home/ubuntu/CardioIA/data/processed')\n",
    "data_processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(str(data_processed_dir / 'X_train.npy'), X_train)\n",
    "np.save(str(data_processed_dir / 'X_val.npy'), X_val)\n",
    "np.save(str(data_processed_dir / 'X_test.npy'), X_test)\n",
    "np.save(str(data_processed_dir / 'y_train.npy'), y_train)\n",
    "np.save(str(data_processed_dir / 'y_val.npy'), y_val)\n",
    "np.save(str(data_processed_dir / 'y_test.npy'), y_test)\n",
    "\n",
    "print(f\"‚úì Arquivos salvos em: {data_processed_dir}\")\n",
    "\n",
    "# Visualizar distribui√ß√£o\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "fig.suptitle('Distribui√ß√£o de Classes nos Conjuntos de Dados', fontsize=14, fontweight='bold')\n",
    "\n",
    "for ax, (conjunto_nome, y_conjunto) in zip(axes, [('Treino', y_train), ('Valida√ß√£o', y_val), ('Teste', y_test)]):\n",
    "    class_counts = pd.Series(y_conjunto).value_counts().sort_index()\n",
    "    class_names = [classes[i] for i in class_counts.index]\n",
    "    \n",
    "    bars = ax.bar(class_names, class_counts.values, color=['#3498db', '#e74c3c', '#f39c12'])\n",
    "    ax.set_title(f'{conjunto_nome} (n={len(y_conjunto)})')\n",
    "    ax.set_ylabel('N√∫mero de Imagens')\n",
    "    ax.set_ylim(0, max(class_counts.values) * 1.2)\n",
    "    \n",
    "    # Adicionar valores nas barras\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}',\n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/03_distribuicao_conjuntos.png', dpi=150, bbox_inches='tight')\n",
    "print(\"‚úì Visualiza√ß√£o salva: 03_distribuicao_conjuntos.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0592d52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SE√á√ÉO 5: DOCUMENTA√á√ÉO DO PIPELINE\n",
      "================================================================================\n",
      "\n",
      "‚úì Informa√ß√µes do Pipeline salvas em: pipeline_info.json\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SE√á√ÉO 5: DOCUMENTA√á√ÉO DO PIPELINE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SE√á√ÉO 5: DOCUMENTA√á√ÉO DO PIPELINE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "pipeline_info = {\n",
    "    'data_execucao': datetime.now().isoformat(),\n",
    "    'seed': SEED,\n",
    "    'dataset': {\n",
    "        'total_imagens': len(X),\n",
    "        'dimensoes': list(X.shape),\n",
    "        'classes': classes,\n",
    "        'distribuicao': {\n",
    "            'treino': {\n",
    "                'total': int(len(X_train)),\n",
    "                'percentual': float(len(X_train)/len(X)*100)\n",
    "            },\n",
    "            'validacao': {\n",
    "                'total': int(len(X_val)),\n",
    "                'percentual': float(len(X_val)/len(X)*100)\n",
    "            },\n",
    "            'teste': {\n",
    "                'total': int(len(X_test)),\n",
    "                'percentual': float(len(X_test)/len(X)*100)\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'preprocessamento': {\n",
    "        'tecnicas_aplicadas': [\n",
    "            'Redimensionamento (interpola√ß√£o c√∫bica)',\n",
    "            'Equaliza√ß√£o de Histograma',\n",
    "            'Normaliza√ß√£o (0-1)',\n",
    "            'Padroniza√ß√£o (z-score)'\n",
    "        ],\n",
    "        'tamanho_alvo': list(preprocessador.tamanho_alvo),\n",
    "        'intervalo_valores': [float(X.min()), float(X.max())]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Salvar como JSON\n",
    "with open('/home/ubuntu/CardioIA/data/processed/pipeline_info.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(pipeline_info, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"\\n‚úì Informa√ß√µes do Pipeline salvas em: pipeline_info.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "164e4698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RESUMO FINAL - PARTE 1\n",
      "================================================================================\n",
      "\n",
      "‚úì PR√â-PROCESSAMENTO CONCLU√çDO COM SUCESSO!\n",
      "\n",
      "üìä Estat√≠sticas do Dataset:\n",
      "   ‚Ä¢ Total de imagens: 198\n",
      "   ‚Ä¢ Dimens√µes: 224x224 pixels\n",
      "   ‚Ä¢ N√∫mero de canais: 1\n",
      "   ‚Ä¢ N√∫mero de classes: 3\n",
      "\n",
      "üìÅ Divis√£o dos Dados:\n",
      "   ‚Ä¢ Treino:     96 imagens (48.5%)\n",
      "   ‚Ä¢ Valida√ß√£o:  42 imagens (21.2%)\n",
      "   ‚Ä¢ Teste:      60 imagens (30.3%)\n",
      "\n",
      "üîß T√©cnicas de Pr√©-processamento Aplicadas:\n",
      "   1. Redimensionamento (interpola√ß√£o c√∫bica)\n",
      "   2. Equaliza√ß√£o de Histograma\n",
      "   3. Normaliza√ß√£o (escala 0-1)\n",
      "   4. Padroniza√ß√£o (z-score normalization)\n",
      "\n",
      "üìà Intervalo de Valores dos Dados:\n",
      "   ‚Ä¢ M√≠nimo: -2.5000\n",
      "   ‚Ä¢ M√°ximo: -2.4804\n",
      "   ‚Ä¢ M√©dia: -2.4900\n",
      "   ‚Ä¢ Desvio Padr√£o: 0.0057\n",
      "\n",
      "üíæ Arquivos Gerados:\n",
      "   ‚Ä¢ X_train.npy, y_train.npy\n",
      "   ‚Ä¢ X_val.npy, y_val.npy\n",
      "   ‚Ä¢ X_test.npy, y_test.npy\n",
      "   ‚Ä¢ pipeline_info.json\n",
      "\n",
      "üìä Relat√≥rios Visuais:\n",
      "   ‚Ä¢ 01_amostras_dataset.png\n",
      "   ‚Ä¢ 02_antes_depois_preprocessamento.png\n",
      "   ‚Ä¢ 03_distribuicao_conjuntos.png\n",
      "\n",
      "‚úÖ Pr√≥ximo passo: Implementar modelos CNN (PARTE 2)\n",
      "\n",
      "================================================================================\n",
      "Fim da PARTE 1\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# RESUMO FINAL\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RESUMO FINAL - PARTE 1\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\"\"\n",
    "‚úì PR√â-PROCESSAMENTO CONCLU√çDO COM SUCESSO!\n",
    "\n",
    "üìä Estat√≠sticas do Dataset:\n",
    "   ‚Ä¢ Total de imagens: {len(X)}\n",
    "   ‚Ä¢ Dimens√µes: {X.shape[1]}x{X.shape[2]} pixels\n",
    "   ‚Ä¢ N√∫mero de canais: {X.shape[3] if len(X.shape) > 3 else 1}\n",
    "   ‚Ä¢ N√∫mero de classes: {len(classes)}\n",
    "\n",
    "üìÅ Divis√£o dos Dados:\n",
    "   ‚Ä¢ Treino:     {len(X_train)} imagens ({len(X_train)/len(X)*100:.1f}%)\n",
    "   ‚Ä¢ Valida√ß√£o:  {len(X_val)} imagens ({len(X_val)/len(X)*100:.1f}%)\n",
    "   ‚Ä¢ Teste:      {len(X_test)} imagens ({len(X_test)/len(X)*100:.1f}%)\n",
    "\n",
    "üîß T√©cnicas de Pr√©-processamento Aplicadas:\n",
    "   1. Redimensionamento (interpola√ß√£o c√∫bica)\n",
    "   2. Equaliza√ß√£o de Histograma\n",
    "   3. Normaliza√ß√£o (escala 0-1)\n",
    "   4. Padroniza√ß√£o (z-score normalization)\n",
    "\n",
    "üìà Intervalo de Valores dos Dados:\n",
    "   ‚Ä¢ M√≠nimo: {X.min():.4f}\n",
    "   ‚Ä¢ M√°ximo: {X.max():.4f}\n",
    "   ‚Ä¢ M√©dia: {X.mean():.4f}\n",
    "   ‚Ä¢ Desvio Padr√£o: {X.std():.4f}\n",
    "\n",
    "üíæ Arquivos Gerados:\n",
    "   ‚Ä¢ X_train.npy, y_train.npy\n",
    "   ‚Ä¢ X_val.npy, y_val.npy\n",
    "   ‚Ä¢ X_test.npy, y_test.npy\n",
    "   ‚Ä¢ pipeline_info.json\n",
    "\n",
    "üìä Relat√≥rios Visuais:\n",
    "   ‚Ä¢ 01_amostras_dataset.png\n",
    "   ‚Ä¢ 02_antes_depois_preprocessamento.png\n",
    "   ‚Ä¢ 03_distribuicao_conjuntos.png\n",
    "\n",
    "‚úÖ Pr√≥ximo passo: Implementar modelos CNN (PARTE 2)\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Fim da PARTE 1\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiap",
   "language": "python",
   "name": "fiap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
